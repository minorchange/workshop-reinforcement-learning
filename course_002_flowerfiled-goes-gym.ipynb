{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets \"standardize\" the Flower Filed\n",
    "\n",
    "From [https://gym.openai.com/](https://gym.openai.com/): \n",
    "\"Gym is a toolkit for developing and comparing reinforcement learning algorithms.\"\n",
    "\n",
    "Gym has expectations on how a environment for reinforcement learning should behave. For example the following functions must be implemented:\n",
    "- step\n",
    "- reset\n",
    "\n",
    "and the following member variables must be defined:\n",
    "- action_space\n",
    "- observation_space\n",
    "\n",
    "Before we adapt our FlowerField in a way that makes it compatible with gym, lets talk about the action_space and the observation_space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaces\n",
    "\n",
    "Gym expects that both the actions (the thing that the agent does to interact with the environment) and the observations (the observable state of the environment) are formulated in a special way: A gym.space.\n",
    "There are different kind of spaces. Lets splay with some examples to get a feeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "gym.logger.set_level(40)\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "\n",
    "d = Discrete(3)\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.685123, 100.66234 ], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Box(low=np.array([0, 100]), high=np.array([41, 102]))\n",
    "b.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more kind of Spaces and it is possible to combine them to express more complicated settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlowerField the Gym way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_002_FlowerFieldEnv import FlowerFiledEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "env = FlowerFiledEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 468.808657909591, Average Reward: 9.37617315819182, Stepcount: 50\n",
      "Episode: 2, Score: 480.28566290308447, Average Reward: 9.605713258061689, Stepcount: 50\n",
      "Episode: 3, Score: 494.1300835925612, Average Reward: 9.882601671851225, Stepcount: 50\n",
      "Episode: 4, Score: 488.28093444088734, Average Reward: 9.765618688817746, Stepcount: 50\n",
      "Episode: 5, Score: 462.73839367964166, Average Reward: 9.254767873592833, Stepcount: 50\n"
     ]
    }
   ],
   "source": [
    "from course_002_FlowerFieldEnv import FlowerFiledEnv\n",
    "from course_001_Bumblebee import Bumblebee\n",
    "\n",
    "\n",
    "env = FlowerFiledEnv()\n",
    "bb = Bumblebee()\n",
    "\n",
    "n_episodes = 5\n",
    "for ep in range(1, n_episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0  \n",
    "    stepcount = 0\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action = bb.choose_flower() # Bumblebee Acting\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        stepcount += 1\n",
    "        bb.update_memory(action, reward) # Bumblebee Learning\n",
    "        score+=reward\n",
    "    print(f'Episode: {ep}, Score: {score}, Average Reward: {score/stepcount}, Stepcount: {stepcount}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now why was it a good idea again to use this clunky gym style?\n",
    "\n",
    "Lets have a look at the next chapter :)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13f74e600e5db7500a78e4d27f86aa859591adaab4fefda8dd94987a559e0a34"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
