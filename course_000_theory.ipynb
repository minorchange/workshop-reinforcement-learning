{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import course_000_Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it fit in the Machine Learning Landscape?\n",
    "One can divide Machine Learning approaches into 3 categories\n",
    "- **Supervised Learning** aims to learn a mapping from an input to an output based on given input-output pairs.\n",
    "- **Unsupervised Learning** is the domain, where patterns are found from untagged data.\n",
    "- **Reinforcement Learning** is concerned with figuring out a suitable policy for an intelligent agent to take strategic actions in a given environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning### Lets Break it down:\n",
    "- What is this intelligent agent?\n",
    "- What does environment mean in this context?\n",
    "- What about the policy?\n",
    "- How is strategy involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent vs Environment\n",
    "\n",
    "Lets talk about the first 3 questions here. They are way easier to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/agent_environment_diag.png\" alt=\"Drawing\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent\n",
    "\n",
    "is an entity that can interact with the environment only via a specified set of actions. After each action the agent gets 2 pieces of information from the environment:\n",
    "1. **The Observation** is the state of the environment after the action took effect and\n",
    "2. **A Reward** that the agent is trying to maximize in the long term by choosing its actions accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Environment\n",
    "\n",
    "is the representation of the scenario that the agent has to cope with. It does not need to be deterministic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Policy\n",
    "\n",
    "The Agent who sees the current Observation comes up with a respective Action according to his Policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Strategy?\n",
    "\n",
    "Example: Suppose you want to teach your algorithm the game of chess. You have to decide how to praise and blame your Agent during training. One way would be to praise the algorithm for a won game and to blame it for a lost game. The agent has the freedom to learn how sacrificing pieces can lead to overall beneficial outcomes. In other words the algorithm can prioritize expected big long term benefits over smaller short term ones."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13f74e600e5db7500a78e4d27f86aa859591adaab4fefda8dd94987a559e0a34"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
